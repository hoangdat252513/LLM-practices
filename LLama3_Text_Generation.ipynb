{"cells":[{"cell_type":"markdown","metadata":{"id":"KfGs45QWa-Rz"},"source":["https://levelup.gitconnected.com/building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2\n","\n","https://levelup.gitconnected.com/building-an-ai-text-to-video-model-from-scratch-using-python-35b4eb4002de"]},{"cell_type":"markdown","metadata":{"id":"vxfzjBacGbYp"},"source":["# config"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56955,"status":"ok","timestamp":1737650185178,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"ESi903jNGJBl","outputId":"155a4002-e465-4c9c-8c5a-08069810dbcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 34.7 ms (started: 2025-01-23 16:36:23 +00:00)\n"]}],"source":["%%capture\n","\n","%pip install -U sentencepiece tiktoken blobfile huggingface_hub\n","%pip install -U -q lightning transformers\n","%pip install ipython-autotime\n","\n","%load_ext autotime\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"VyYUkow1EHCt"},"source":["# code loop style"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8285,"status":"ok","timestamp":1737647382657,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"JVL4gCqGOM-G","outputId":"ba3a14fc-dcc3-47be-da2c-0d0b4818f29c"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 8.18 s (started: 2025-01-23 15:49:32 +00:00)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import tiktoken\n","from tiktoken.load import load_tiktoken_bpe\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from collections import OrderedDict\n","\n","import urllib.request\n","import time\n","import json\n","import matplotlib.pyplot as plt\n","# from huggingface_hub import notebook_login\n","# notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"p05lFkYfnlBa"},"source":["## preprocess data"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":553,"status":"ok","timestamp":1737647617790,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"SKTmSaYpLIHH","outputId":"5018469f-5d63-4a8a-9866-af0feb81c36f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Printing the first 10 characters of the vocab list: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3']\n","Total number of characters in our dataset (Vocabulary Size): 65\n","time: 194 ms (started: 2025-01-23 15:53:35 +00:00)\n"]}],"source":["# The URL of the raw text file on GitHub\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","\n","# The file name for local storage\n","file_name = \"tinyshakespeare.txt\"\n","\n","# Execute the download\n","urllib.request.urlretrieve(url, file_name)\n","# Read the content of the dataset\n","lines = open(\"tinyshakespeare.txt\", 'r').read()\n","\n","# Create a sorted list of unique characters in the dataset\n","vocab = sorted(list(set(lines)))\n","\n","# Display the first 10 characters in the vocabulary list\n","print('Printing the first 10 characters of the vocab list:', vocab[:10])\n","\n","# Output the total number of characters in our dataset (Vocabulary Size)\n","print('Total number of characters in our dataset (Vocabulary Size):', len(vocab))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1737647618322,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"72StSG8cLLiy","outputId":"461cf2c1-fe57-4071-ab69-da318f4345d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115394])\n","time: 258 ms (started: 2025-01-23 15:53:35 +00:00)\n"]}],"source":["# Mapping integers to characters (itos)\n","itos = {i: ch for i, ch in enumerate(vocab)}\n","\n","# Mapping characters to integers (stoi)\n","stoi = {ch: i for i, ch in enumerate(vocab)}\n","\n","# Encode function: Converts a string to a list of integers using the mapping stoi\n","def encode(s):\n","    return [stoi[ch] for ch in s]\n","\n","# Decode function: Converts a list of integers back to a string using the mapping itos\n","def decode(l):\n","    return ''.join([itos[i] for i in l])\n","\n","# Convert the dataset into a torch tensor with specified data type (dtype)\n","dataset = torch.tensor(encode(lines), dtype=torch.int8)\n","\n","# Display the shape of the resulting tensor\n","print(dataset.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":393,"status":"ok","timestamp":1737647620499,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"5fgd5tFeOn_O","outputId":"7c47041e-247f-43d6-ab0a-1025f5c268ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 82.9 ms (started: 2025-01-23 15:53:38 +00:00)\n"]}],"source":["MASTER_CONFIG = {}\n","# Function to get batches for training, validation, or testing\n","def get_batches(data, split, batch_size, context_window, config=MASTER_CONFIG):\n","    # Split the dataset into training, validation, and test sets\n","    train = data[:int(.8 * len(data))]\n","    val = data[int(.8 * len(data)): int(.9 * len(data))]\n","    test = data[int(.9 * len(data)):]\n","\n","    # Determine which split to use\n","    batch_data = train\n","    if split == 'val':\n","        batch_data = val\n","    if split == 'test':\n","        batch_data = test\n","\n","    # Pick random starting points within the data\n","    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n","\n","    # Create input sequences (x) and corresponding target sequences (y)\n","    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n","    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n","\n","    return x, y"]},{"cell_type":"code","source":["MASTER_CONFIG.update({\n","    'batch_size': 32,          # Number of batches to be processed at each random split\n","    'context_window': 16,    # Number of characters in each input (x) and target (y) sequence of each batch\n","    'd_model': 128,\n","    \"vocab_size\":len(vocab),\n","})\n","# Obtain batches for training using the specified batch size and context window\n","xs, ys = get_batches(dataset, 'train', MASTER_CONFIG['batch_size'], MASTER_CONFIG['context_window'])\n","\n","# Decode the sequences to obtain the corresponding text representations\n","decoded_samples = [(decode(xs[i].tolist()), decode(ys[i].tolist())) for i in range(len(xs))]\n","\n","# Print the random sample\n","print(decoded_samples)\n","\n","xs.shape, ys.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pbm_wDxgtLmx","executionInfo":{"status":"ok","timestamp":1737647624754,"user_tz":-420,"elapsed":339,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"17832014-c6e9-4f01-d60e-3a9a3ec0e4e3"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 16]), torch.Size([32, 16]))"]},"metadata":{},"execution_count":19},{"output_type":"stream","name":"stdout","text":["time: 71.5 ms (started: 2025-01-23 15:53:42 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"nedgPHoe2LHd"},"source":["## model training func"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1737647695045,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"jQZQNtcEO-L-","outputId":"6262fb23-69b9-4445-e324-3548ce83afb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 115 ms (started: 2025-01-23 15:54:52 +00:00)\n"]}],"source":["@torch.no_grad()  # Don't compute gradients for this function\n","def evaluate_loss(model, config=MASTER_CONFIG):\n","    out = {}\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Iterate through training and validation splits\n","    for split in [\"train\", \"val\"]:\n","        losses = []\n","        # Generate 10 batches for evaluation\n","        for _ in range(10):\n","            # Get input sequences (xb) and target sequences (yb)\n","            xb, yb = get_batches(dataset, split, config['batch_size'], config['context_window'])\n","\n","            # Perform model inference and calculate the loss\n","            _, loss = model(xb, yb)\n","\n","            # Append the loss to the list\n","            losses.append(loss.item())\n","\n","        # Calculate the mean loss for the split and store it in the output dictionary\n","        out[split] = np.mean(losses)\n","\n","    # Set the model back to training mode\n","    model.train()\n","\n","    return out"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1737647695045,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"6pcJy-kEP6JI","outputId":"ca87033e-22eb-4e0e-b6a7-a9cbb211bb41"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 96.5 ms (started: 2025-01-23 15:54:53 +00:00)\n"]}],"source":["from tqdm import tqdm\n","\n","# Function to perform training\n","def train(model, optimizer, scheduler=None, config=MASTER_CONFIG, print_logs=False):\n","    # Placeholder for storing losses\n","    losses = []\n","\n","    # set model to training mode\n","    model.train()\n","\n","    # Start tracking time\n","    start_time = time.time()\n","\n","    # Iterate through epochs\n","    for epoch in tqdm(range(config['epochs'])):\n","        # Zero out gradients\n","        optimizer.zero_grad()\n","\n","        # Obtain batches for training\n","        xs, ys = get_batches(dataset, 'train', config['batch_size'], config['context_window'])\n","\n","        # Forward pass through the model to calculate logits and loss\n","        logits, loss = model(xs, targets=ys)\n","\n","        # Backward pass and optimization step\n","        loss.backward()\n","        optimizer.step()\n","\n","        # If a learning rate scheduler is provided, adjust the learning rate\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Log progress every specified interval\n","        if epoch % config['log_interval'] == 0:\n","            # Calculate batch time\n","            batch_time = time.time() - start_time\n","\n","            # Evaluate loss on validation set\n","            x = evaluate_loss(model)\n","\n","            # Store the validation loss\n","            losses += [x]\n","\n","            # Print progress logs if specified\n","            if print_logs:\n","                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config['epochs'] - epoch)/config['log_interval'] :.3f}\")\n","\n","            # Reset the timer\n","            start_time = time.time()\n","\n","            # Print learning rate if a scheduler is provided\n","            if scheduler:\n","                print(\"lr: \", scheduler.get_lr())\n","\n","    # Print the final validation loss\n","    print(\"Validation loss: \", losses[-1]['val'])\n","\n","    # Plot the training and validation loss curves\n","    return pd.DataFrame(losses).plot()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1737647697770,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"sOm6SjktQcQV","outputId":"0fe76ecf-f42a-4f53-c206-b5de5c976476"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 391 ms (started: 2025-01-23 15:54:55 +00:00)\n"]}],"source":["# Generate function for text generation using the trained model\n","def generate(model, config=MASTER_CONFIG, max_new_tokens=30):\n","    idx = torch.zeros(5, 1).long()\n","    for _ in range(max_new_tokens):\n","        # Call the model\n","        logits = model(idx[:, -config['context_window']:])\n","        last_time_step_logits = logits[\n","            :, -1, :\n","        ]  # all the batches (1), last time step, all the logits\n","        p = F.softmax(last_time_step_logits, dim=-1)  # softmax to get probabilities\n","        idx_next = torch.multinomial(\n","            p, num_samples=1\n","        )  # sample from the distribution to get the next token\n","        idx = torch.cat([idx, idx_next], dim=-1)  # append to the sequence\n","    return [decode(x) for x in idx.tolist()]"]},{"cell_type":"markdown","metadata":{"id":"AJDUaLanQegx"},"source":["##  LLaMA Architecture\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1737197290771,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"Cyslxrh2Q_ab","outputId":"f0f6433c-f4ce-4e07-d7d3-f26acd89907f"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 63.7 ms (started: 2025-01-18 10:48:10 +00:00)\n"]}],"source":["class RMSNorm(nn.Module):\n","    def __init__(self, layer_shape, eps=1e-8, bias=False):\n","        super(RMSNorm, self).__init__()\n","\n","        # Registering a learnable parameter 'scale' as a parameter of the module\n","        self.register_parameter(\"scale\", nn.Parameter(torch.ones(layer_shape)))\n","    def forward(self, x):\n","        \"\"\"\n","        Assumes shape is (batch, seq_len, d_model)\n","        \"\"\"\n","        # Calculating the Frobenius norm, RMS = 1/sqrt(N) * Frobenius norm\n","        ff_rms = torch.linalg.norm(x, dim=(1,2)) * x[0].numel() ** -.5\n","\n","        # Normalizing the input tensor 'x' with respect to RMS\n","        raw = x / ff_rms.unsqueeze(-1).unsqueeze(-1)\n","\n","        # Scaling the normalized tensor using the learnable parameter 'scale'\n","        return self.scale[:x.shape[1], :].unsqueeze(0) * raw\n","\n","\n","class RoPEMaskedAttentionHead(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        # Linear transformation for query\n","        self.w_q = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Linear transformation for key\n","        self.w_k = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Linear transformation for value\n","        self.w_v = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Obtain rotary matrix for positional embeddings\n","        self.R = self.get_rotary_matrix(config['context_window'], config['d_model'])\n","\n","    def get_rotary_matrix(self, context_window, embedding_dim):\n","        # Initialize a tensor for the rotary matrix with zeros\n","        R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n","\n","        # Loop through each position in the context window\n","        for position in range(context_window):\n","            # Loop through each dimension in the embedding\n","            for i in range(embedding_dim // 2):\n","                # Calculate the rotation angle (theta) based on the position and embedding dimension\n","                theta = 10000. ** (-2. * (i - 1) / embedding_dim)\n","                # Calculate the rotated matrix elements using sine and cosine functions\n","                m_theta = position * theta\n","                R[position, 2 * i, 2 * i] = np.cos(m_theta)\n","                R[position, 2 * i, 2 * i + 1] = -np.sin(m_theta)\n","                R[position, 2 * i + 1, 2 * i] = np.sin(m_theta)\n","                R[position, 2 * i + 1, 2 * i + 1] = np.cos(m_theta)\n","        return R\n","\n","\n","    def forward(self, x, return_attn_weights=False):\n","        # x: input tensor of shape (batch_size, sequence length, dimension)\n","\n","        b, m, d = x.shape  # batch size, sequence length, dimension\n","\n","        # Linear transformations for Q, K, and V\n","        q = self.w_q(x)\n","        k = self.w_k(x)\n","        v = self.w_v(x)\n","\n","        # Rotate Q and K using the RoPE matrix\n","        q_rotated = (torch.bmm(q.transpose(0, 1), self.R[:m])).transpose(0, 1)\n","        k_rotated = (torch.bmm(k.transpose(0, 1), self.R[:m])).transpose(0, 1)\n","\n","        # Perform scaled dot-product attention\n","        activations = F.scaled_dot_product_attention(\n","            q_rotated, k_rotated, v, dropout_p=0.1, is_causal=True\n","        )\n","\n","        if return_attn_weights:\n","            # Create a causal attention mask\n","            attn_mask = torch.tril(torch.ones((m, m)), diagonal=0)\n","            # Calculate attention weights and add causal mask\n","            attn_weights = torch.bmm(q_rotated, k_rotated.transpose(1, 2)) / np.sqrt(d) + attn_mask\n","            attn_weights = F.softmax(attn_weights, dim=-1)\n","            return activations, attn_weights\n","\n","        return activations\n","\n","class RoPEMaskedMultiheadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        # Create a list of RoPEMaskedAttentionHead instances as attention heads\n","        self.heads = nn.ModuleList([\n","            RoPEMaskedAttentionHead(config) for _ in range(config['n_heads'])\n","        ])\n","        self.linear = nn.Linear(config['n_heads'] * config['d_model'], config['d_model'])  # Linear layer after concatenating heads\n","        self.dropout = nn.Dropout(.1)  # Dropout layer\n","\n","    def forward(self, x):\n","        # x: input tensor of shape (batch, sequence length, dimension)\n","\n","        # Process each attention head and concatenate the results\n","        heads = [h(x) for h in self.heads]\n","        x = torch.cat(heads, dim=-1)\n","\n","        # Apply linear transformation to the concatenated output\n","        x = self.linear(x)\n","\n","        # Apply dropout\n","        x = self.dropout(x)\n","        return x\n","\n","class SwiGLU(nn.Module):\n","    \"\"\" Paper Link -> https://arxiv.org/pdf/2002.05202v1.pdf \"\"\"\n","    def __init__(self, size):\n","        super().__init__()\n","        self.linear_gate = nn.Linear(size, size)  # Linear transformation for the gating mechanism\n","        self.linear = nn.Linear(size, size)  # Linear transformation for the main branch\n","        self.beta = torch.randn(1, requires_grad=True)  # Random initialization of the beta parameter\n","\n","        # Using nn.Parameter for beta to ensure it's recognized as a learnable parameter\n","        self.beta = nn.Parameter(torch.ones(1))\n","        self.register_parameter(\"beta\", self.beta)\n","\n","    def forward(self, x):\n","        # Swish-Gated Linear Unit computation\n","        swish_gate = self.linear_gate(x) * torch.sigmoid(self.beta * self.linear_gate(x))\n","        out = swish_gate * self.linear(x)  # Element-wise multiplication of the gate and main branch\n","        return out"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1737647744621,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"PKYN_1WFRLz4","outputId":"3aa78738-59b8-46ca-83f1-72cd28146a95"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 129 ms (started: 2025-01-23 15:55:42 +00:00)\n"]}],"source":["# add RMSNorm and residual connection\n","class LlamaBlock(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        # RMSNorm layer\n","        self.rms = RMSNorm((config['context_window'], config['d_model']))\n","\n","        # RoPE Masked Multihead Attention layer\n","        self.attention = RoPEMaskedMultiheadAttention(config)\n","\n","        # Feedforward layer with SwiGLU activation\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(config['d_model'], config['d_model']),\n","            SwiGLU(config['d_model']),\n","        )\n","\n","    def forward(self, x):\n","        # one block of attention\n","        x = self.rms(x) # RMS pre-normalization\n","        x = x + self.attention(x)  # residual connection\n","\n","        x = self.rms(x) # RMS pre-normalization\n","        x = x + self.feedforward(x)  # residual connection\n","        return x\n","\n","class Llama(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        # Embedding layer for token representations\n","        self.embeddings = nn.Embedding(config['vocab_size'], config['d_model'])\n","        # Sequential block of LlamaBlocks based on the specified number of layers\n","        self.llama_blocks = nn.Sequential(\n","            OrderedDict([(f\"llama_{i}\", LlamaBlock(config)) for i in range(config['n_layers'])])\n","        )\n","        # Feedforward network (FFN) for final output\n","        self.ffn = nn.Sequential(\n","            nn.Linear(config['d_model'], config['d_model']),\n","            SwiGLU(config['d_model']),\n","            nn.Linear(config['d_model'], config['vocab_size']),\n","        )\n","\n","        # Print total number of parameters in the model\n","        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n","\n","    def forward(self, idx, targets=None):\n","        # Input token indices are passed through the embedding layer\n","        x = self.embeddings(idx)\n","        # Process the input through the LlamaBlocks\n","        x = self.llama_blocks(x)\n","        # Pass the processed input through the final FFN for output logits\n","        logits = self.ffn(x)\n","\n","        # If targets are not provided, return only the logits\n","        if targets is None:\n","            return logits\n","        # If targets are provided, compute and return the cross-entropy loss\n","        else:\n","            loss = F.cross_entropy(logits.view(-1, self.config['vocab_size']), targets.view(-1))\n","            return logits, loss"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5ofWbDSnYvx","outputId":"7e6ddd95-172a-48e3-c4ee-202f00ea3046","executionInfo":{"status":"ok","timestamp":1737647765463,"user_tz":-420,"elapsed":3807,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["model params: 2370246\n","time: 3.65 s (started: 2025-01-23 15:55:59 +00:00)\n"]}],"source":["MASTER_CONFIG = {\n","    'batch_size': 64,\n","    'context_window': 16,\n","    'd_model': 128,\n","    'vocab_size': 65,\n","    'epochs': 5000,\n","    'log_interval': 10,\n","    'n_heads': 8,\n","    'n_layers': 4\n","}\n","\n","# Create an instance of RopeModel (RMSNorm, RoPE, Multi-Head, SwiGLU, N_layers)\n","llama = Llama(MASTER_CONFIG)\n","\n","# Obtain batches for training\n","xs, ys = get_batches(dataset, 'train', MASTER_CONFIG['batch_size'], MASTER_CONFIG['context_window'])\n","\n","# Calculate logits and loss using the model\n","logits, loss = llama(xs, ys)"]},{"cell_type":"code","source":["xs.shape, ys.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mie76W0b8fAS","executionInfo":{"status":"ok","timestamp":1737648906541,"user_tz":-420,"elapsed":474,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"b05e021c-e025-4d86-aff6-4f2263ed6bb8"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([64, 16]), torch.Size([64, 16]))"]},"metadata":{},"execution_count":50},{"output_type":"stream","name":"stdout","text":["time: 178 ms (started: 2025-01-23 16:15:04 +00:00)\n"]}]},{"cell_type":"code","source":["logits.shape, loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUOo47ho4O-X","executionInfo":{"status":"ok","timestamp":1737647814526,"user_tz":-420,"elapsed":366,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"07681b5d-6593-4b8c-b8b4-95e82f72089a"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([64, 16, 65]), tensor(4.1688, grad_fn=<NllLossBackward0>))"]},"metadata":{},"execution_count":33},{"output_type":"stream","name":"stdout","text":["time: 97.3 ms (started: 2025-01-23 15:56:52 +00:00)\n"]}]},{"cell_type":"code","source":["# Define the Adam optimizer for model parameters\n","optimizer = torch.optim.Adam(llama.parameters())\n","\n","train(llama, optimizer, config=MASTER_CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCxIotk57TNB","executionInfo":{"status":"ok","timestamp":1737296263486,"user_tz":-420,"elapsed":377,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"f92a3260-8328-4d39-f2b4-347155650f95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 126 ms (started: 2025-01-19 14:17:42 +00:00)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrTsuvtNRXY7"},"outputs":[],"source":["generated_text = generate(llama, MASTER_CONFIG, 500)[0]\n","print(generated_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c5aqvgJRY9g"},"outputs":[],"source":["# Get batches from the test set\n","xs, ys = get_batches(dataset, 'test', MASTER_CONFIG['batch_size'], MASTER_CONFIG['context_window'])\n","\n","# Pass the test data through the LLaMA model\n","logits, loss = llama(xs, ys)\n","\n","# Print the loss on the test set\n","print(loss)"]},{"cell_type":"markdown","metadata":{"id":"SjLse7PiB6Hv"},"source":["# Torch lightning module"]},{"cell_type":"markdown","metadata":{"id":"RdcyVAzWB-SP"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XBxNiGeFDOPQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737650212887,"user_tz":-420,"elapsed":27714,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"bf1b5472-4127-4c7d-c530-310126dfce16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random seed set as 0\n","time: 27.4 s (started: 2025-01-23 16:36:23 +00:00)\n"]}],"source":["from glob import glob\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import os\n","from tqdm import tqdm\n","import regex as re\n","from sklearn.model_selection import train_test_split\n","from collections import OrderedDict\n","import random\n","import urllib.request\n","import time\n","import json\n","\n","import lightning.pytorch as L  # For PyTorch Lightning functionality\n","from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping  # Model callbacks\n","from lightning.pytorch.callbacks import ModelSummary  # For summarizing model architecture\n","from lightning.pytorch import Trainer, seed_everything\n","import torchmetrics  # For PyTorch metrics computation\n","import torch  # For PyTorch deep learning framework\n","from torch import nn  # For building neural network modules\n","from torch.nn import functional as F\n","import torchvision  # For computer vision utilities and datasets\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from transformers import AutoTokenizer, AutoModel\n","\n","\n","import tiktoken\n","from tiktoken.load import load_tiktoken_bpe\n","\n","# import nltk\n","# from nltk.tokenize import word_tokenize\n","# from nltk.corpus import stopwords\n","# nltk.download('stopwords')\n","# nltk.download('punkt')\n","# nltk.download('punkt_tab')\n","\n","def set_seed(seed: int = 0) -> None:\n","    \"\"\"Set random seed for reproducibility across numpy, random, torch, and CUDA.\"\"\"\n","    np.random.seed(seed)  # Seed for numpy operations\n","    random.seed(seed)  # Seed for random module\n","    torch.manual_seed(seed)  # Seed for PyTorch on CPU\n","    torch.cuda.manual_seed(seed)  # Seed for PyTorch on CUDA GPU\n","\n","    # Ensure reproducibility on CuDNN backend\n","    torch.backends.cudnn.deterministic = True  # Disable nondeterministic algorithms\n","    torch.backends.cudnn.benchmark = False  # Disable performance optimizations for determinism\n","\n","    # Set a fixed value for the hash seed for reproducibility\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    print(f\"Random seed set as {seed}\")  # Confirm seed setting\n","\n","# Set default seed for reproducibility\n","set_seed()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1737650212888,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"outputId":"3112da8d-a75d-4c0b-88fd-d545284955a0","id":"qqp6Yw6mJX97"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 362 ms (started: 2025-01-23 16:36:50 +00:00)\n"]}],"source":["# The URL of the raw text file on GitHub\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","\n","# The file name for local storage\n","file_name = \"tinyshakespeare.txt\"\n","\n","# Execute the download\n","urllib.request.urlretrieve(url, file_name)\n","\n","# Read the content of the dataset\n","data_text = open(\"tinyshakespeare.txt\", 'r').read()"]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, text, label, tokenizer, max_length):\n","        self.text = text\n","        self.label = label\n","        self.tokenizer = tokenizer # used pre-trained tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, idx):\n","        # text = str(self.text[idx])\n","        # label = str(self.label[idx])\n","        # try:\n","        #     encoding = self.tokenizer.encode_plus(\n","        #         text,\n","        #         add_special_tokens=True,\n","        #         max_length=self.max_length,\n","        #         padding=\"max_length\",\n","        #         truncation=True,\n","        #         return_tensors=\"pt\",\n","        #     )\n","        #     label_encoding = self.tokenizer.encode_plus(\n","        #         label,\n","        #         add_special_tokens=True,\n","        #         max_length=self.max_length,\n","        #         padding=\"max_length\",\n","        #         truncation=True,\n","        #         return_tensors=\"pt\",\n","        #     )\n","        # except Exception as e:\n","        #     raise ValueError(f\"Error in tokenization: {e}\")\n","\n","\n","        # input_ids = encoding[\"input_ids\"].squeeze()\n","        # attention_mask = encoding[\"attention_mask\"].squeeze()\n","        # labels = label_encoding[\"input_ids\"].squeeze()\n","\n","        # assert input_ids.shape[0] == attention_mask.shape[0] == labels.shape[0] == self.max_length\n","        # assert input_ids.max() < self.tokenizer.vocab_size, \"Input contains indices out of range.\"\n","\n","        # return {\n","        #     \"input_ids\": input_ids,\n","        #     \"attention_mask\": attention_mask,\n","        #     \"label\": labels\n","        # }\n","        return {\n","            \"input_ids\": self.text[idx],\n","            \"label\": self.label[idx]\n","        }\n","\n","class LLamaDataModule(L.LightningDataModule):\n","    def __init__(self, config, data_text):\n","        super().__init__()\n","        self.config = config\n","        # self.data_text = torch.tensor([ord(char) for char in data_text], dtype = torch.long)\n","        self.data_text = data_text\n","        # Actual tokenizer of Llama architecture is SentencePiece Byte-pair encoding\n","        # https://github.com/google/sentencepiece\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.config[\"tokenizer_model\"])\n","        self.vocab_size = self.config[\"vocab_size\"]\n","        self.context_window = self.config[\"context_window\"]\n","        self.batch_size = self.config[\"batch_size\"]\n","        self.num_workers = self.config[\"num_workers\"]\n","\n","    # Encode function: Converts a string to a list of integers using the mapping stoi\n","    def encode(self, input_text):\n","        return [self.stoi[ch] for ch in input_text]\n","\n","    # Decode function: Converts a list of integers back to a string using the mapping itos\n","    def decode(self, input_ids):\n","        return ''.join([itos[i] for i in input_ids])\n","\n","    def setup(self, stage=None):\n","        # Create a sorted list of unique characters in the dataset\n","        vocab = sorted(list(set(self.data_text)))\n","        # Mapping integers to characters (itos)\n","        itos = {i: ch for i, ch in enumerate(vocab)}\n","        # Mapping characters to integers (stoi)\n","        stoi = {ch: i for i, ch in enumerate(vocab)}\n","        self.stoi = stoi\n","        self.itos = itos\n","        # Convert the dataset into a torch tensor with specified data type (dtype)\n","        self.dataset = torch.tensor(self.encode(self.data_text), dtype = torch.int8)\n","\n","        # pick random starting point within data\n","        # ix  = torch.randint(0, len(self.dataset) - self.context_window -1, (self.batch_size, ))\n","        indices = torch.arange(len(self.dataset) - self.context_window)\n","        self.text = torch.stack(\n","            [self.dataset[i:i + self.context_window] for i in indices]\n","        ).long()\n","        self.label = torch.stack(\n","            [self.dataset[i + 1:i + self.context_window + 1] for i in indices]\n","        ).long()\n","\n","        # self.text = self.dataset.unfold(0, self.context_window, 1)[ix]\n","        # self.label = self.dataset.unfold(0, self.context_window, 1)[ix + 1]\n","\n","        # split dataset into train, val, test\n","        text_train, text_val, label_train, label_val = train_test_split(\n","            self.text, self.label, test_size=0.2, random_state=0, shuffle = True\n","        )\n","        text_val, text_test, label_val, label_test = train_test_split(\n","            text_val, label_val, test_size=0.5, random_state=0, shuffle = True\n","        )\n","\n","        self.train_dataset  = CustomDataset(text_train, label_train, self.tokenizer, self.vocab_size)\n","        self.val_dataset = CustomDataset(text_val, label_val, self.tokenizer, self.vocab_size)\n","        self.test_dataset = CustomDataset(text_test, label_test, self.tokenizer, self.vocab_size)\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=self.num_workers\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.num_workers\n","        )\n","\n","    def test_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers = self.num_workers\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZHkwmqPLbzc","executionInfo":{"status":"ok","timestamp":1737650213257,"user_tz":-420,"elapsed":372,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"c41354f9-5d01-41e7-d4d0-11d330ca4d5b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 100 ms (started: 2025-01-23 16:36:51 +00:00)\n"]}]},{"cell_type":"markdown","source":["## LLama module"],"metadata":{"id":"KiZJZqcepBoK"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"5IylLAm19Pn0"}},{"cell_type":"markdown","source":["### LLama components"],"metadata":{"id":"MIsuvHgNoHPT"}},{"cell_type":"code","source":["class RMSNorm(nn.Module):\n","    def __init__(self, layer_shape, eps=1e-8, bias=False):\n","        super(RMSNorm, self).__init__()\n","\n","        # Registering a learnable parameter 'scale' as a parameter of the module\n","        self.register_parameter(\"scale\", nn.Parameter(torch.ones(layer_shape)))\n","    def forward(self, x):\n","        \"\"\"\n","        Assumes shape is (batch, seq_len, d_model)\n","        \"\"\"\n","        # Calculating the Frobenius norm, RMS = 1/sqrt(N) * Frobenius norm\n","        ff_rms = torch.linalg.norm(x, dim=(1,2)) * x[0].numel() ** -.5\n","\n","        # Normalizing the input tensor 'x' with respect to RMS\n","        raw = x / ff_rms.unsqueeze(-1).unsqueeze(-1)\n","\n","        # Scaling the normalized tensor using the learnable parameter 'scale'\n","        return self.scale[:x.shape[1], :].unsqueeze(0) * raw\n","\n","\n","class RoPEMaskedAttentionHead(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        # Linear transformation for query\n","        self.w_q = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Linear transformation for key\n","        self.w_k = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Linear transformation for value\n","        self.w_v = nn.Linear(config['d_model'], config['d_model'], bias=False)\n","        # Obtain rotary matrix for positional embeddings\n","        self.R = self.get_rotary_matrix(config['context_window'], config['d_model'])\n","\n","    def get_rotary_matrix(self, context_window, embedding_dim):\n","        # Initialize a tensor for the rotary matrix with zeros\n","        R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\n","\n","        # Loop through each position in the context window\n","        for position in range(context_window):\n","            # Loop through each dimension in the embedding\n","            for i in range(embedding_dim // 2):\n","                # Calculate the rotation angle (theta) based on the position and embedding dimension\n","                theta = 10000. ** (-2. * (i - 1) / embedding_dim)\n","                # Calculate the rotated matrix elements using sine and cosine functions\n","                m_theta = position * theta\n","                R[position, 2 * i, 2 * i] = np.cos(m_theta)\n","                R[position, 2 * i, 2 * i + 1] = -np.sin(m_theta)\n","                R[position, 2 * i + 1, 2 * i] = np.sin(m_theta)\n","                R[position, 2 * i + 1, 2 * i + 1] = np.cos(m_theta)\n","        return R\n","\n","\n","    def forward(self, x, return_attn_weights=False):\n","        # x: input tensor of shape (batch_size, sequence length, dimension)\n","\n","        b, m, d = x.shape  # batch size, sequence length, dimension\n","\n","        # Linear transformations for Q, K, and V\n","        q = self.w_q(x)\n","        k = self.w_k(x)\n","        v = self.w_v(x)\n","\n","        device = q.device  # Assuming `q` is already on the correct device\n","        self.R = self.R.to(device)  # Move `self.R` to the same device as `q`\n","\n","        # Rotate Q and K using the RoPE matrix\n","        q_rotated = (torch.bmm(q.transpose(0, 1), self.R[:m])).transpose(0, 1)\n","        k_rotated = (torch.bmm(k.transpose(0, 1), self.R[:m])).transpose(0, 1)\n","\n","        # Perform scaled dot-product attention\n","        activations = F.scaled_dot_product_attention(\n","            q_rotated, k_rotated, v, dropout_p=0.1, is_causal=True\n","        )\n","\n","        if return_attn_weights:\n","            # Create a causal attention mask\n","            attn_mask = torch.tril(torch.ones((m, m)), diagonal=0)\n","            # Calculate attention weights and add causal mask\n","            attn_weights = torch.bmm(q_rotated, k_rotated.transpose(1, 2)) / np.sqrt(d) + attn_mask\n","            attn_weights = F.softmax(attn_weights, dim=-1)\n","            return activations, attn_weights\n","\n","        return activations\n","\n","class RoPEMaskedMultiheadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        # Create a list of RoPEMaskedAttentionHead instances as attention heads\n","        self.heads = nn.ModuleList([\n","            RoPEMaskedAttentionHead(config) for _ in range(config['n_heads'])\n","        ])\n","        self.linear = nn.Linear(config['n_heads'] * config['d_model'], config['d_model'])  # Linear layer after concatenating heads\n","        self.dropout = nn.Dropout(.1)  # Dropout layer\n","\n","    def forward(self, x):\n","        # x: input tensor of shape (batch, sequence length, dimension)\n","\n","        # Process each attention head and concatenate the results\n","        heads = [h(x) for h in self.heads]\n","        x = torch.cat(heads, dim=-1)\n","\n","        # Apply linear transformation to the concatenated output\n","        x = self.linear(x)\n","\n","        # Apply dropout\n","        x = self.dropout(x)\n","        return x\n","\n","class SwiGLU(nn.Module):\n","    \"\"\" Paper Link -> https://arxiv.org/pdf/2002.05202v1.pdf \"\"\"\n","    def __init__(self, size):\n","        super().__init__()\n","        self.linear_gate = nn.Linear(size, size)  # Linear transformation for the gating mechanism\n","        self.linear = nn.Linear(size, size)  # Linear transformation for the main branch\n","        self.beta = torch.randn(1, requires_grad=True)  # Random initialization of the beta parameter\n","\n","        # Using nn.Parameter for beta to ensure it's recognized as a learnable parameter\n","        self.beta = nn.Parameter(torch.ones(1))\n","        self.register_parameter(\"beta\", self.beta)\n","\n","    def forward(self, x):\n","        # Swish-Gated Linear Unit computation\n","        swish_gate = self.linear_gate(x) * torch.sigmoid(self.beta * self.linear_gate(x))\n","        out = swish_gate * self.linear(x)  # Element-wise multiplication of the gate and main branch\n","        return out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssMBCJ8VoJGF","executionInfo":{"status":"ok","timestamp":1737651453635,"user_tz":-420,"elapsed":365,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"53105bf0-1296-4a21-d0ab-7cc4c16fb676"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 84.8 ms (started: 2025-01-23 16:57:31 +00:00)\n"]}]},{"cell_type":"markdown","source":["### LLama trainer"],"metadata":{"id":"uK9iPkpfdJNB"}},{"cell_type":"code","source":["# add RMSNorm and residual connection\n","class LlamaBlock(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        # RMSNorm layer\n","        self.rms = RMSNorm((config['context_window'], config['d_model']))\n","\n","        # RoPE Masked Multihead Attention layer\n","        self.attention = RoPEMaskedMultiheadAttention(config)\n","\n","        # Feedforward layer with SwiGLU activation\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(config['d_model'], config['d_model']),\n","            SwiGLU(config['d_model']),\n","        )\n","\n","    def forward(self, x):\n","        # one block of attention\n","        x = self.rms(x) # RMS pre-normalization\n","        x = x + self.attention(x)  # residual connection\n","\n","        x = self.rms(x) # RMS pre-normalization\n","        x = x + self.feedforward(x)  # residual connection\n","        return x\n","\n","class LLamaGeneration(L.LightningModule):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.learning_rate = self.config[\"learning_rate\"]\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.config[\"tokenizer_model\"])\n","        # use pre-trained model\n","        # self.llama_model = AutoModel.from_pretrained(self.config[\"llama_path_pre-trained_model\"])\n","\n","        # or\n","        self.embedding = nn.Embedding(\n","            self.config[\"vocab_size\"],\n","            self.config[\"d_model\"],\n","            # padding_idx=self.tokenizer.pad_token_id\n","        )\n","\n","        self.llama_blocks = nn.Sequential(\n","            OrderedDict([(f\"llama_block{i}\", LlamaBlock(self.config)) for i in range(self.config[\"n_layer\"])])\n","        )\n","\n","        self.fc_layer = nn.Sequential(\n","            # RMSNorm((self.config[\"d_model\"], self.config[\"d_model\"])),\n","            nn.Linear(self.config[\"d_model\"], self.config[\"d_model\"]),\n","            SwiGLU(self.config[\"d_model\"]),\n","            nn.Linear(self.config[\"d_model\"], self.config[\"vocab_size\"])\n","        )\n","\n","    def forward(self, input_idx, attention_mask=None):\n","        # Extract features from pre-trained model\n","        # outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        x = self.embedding(input_idx)\n","        x = self.llama_blocks(x)\n","        logits = self.fc_layer(x)\n","        return logits\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        # attention_mask = batch['attention_mask']\n","        # labels = torch.reshape(batch['label'], (-1, 1))\n","        labels = batch[\"label\"]\n","\n","        # Forward pass and compute loss\n","        predicted_value = self(input_ids)\n","        predicted_value = predicted_value.view(-1, self.config['vocab_size'])\n","        labels = labels.view(-1)\n","\n","        loss = F.cross_entropy(predicted_value, labels)\n","        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)  # Log loss\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        \"\"\"\n","        Performs a single training step.\n","        \"\"\"\n","        input_ids = batch['input_ids']\n","        # attention_mask = batch['attention_mask']\n","        # labels = torch.reshape(batch['label'], (-1, 1))\n","        labels = batch[\"label\"]\n","\n","        # Forward pass and compute loss\n","        predicted_value = self(input_ids)\n","        predicted_value = predicted_value.view(-1, self.config['vocab_size'])\n","        labels = labels.view(-1)\n","\n","        val_loss = F.cross_entropy(predicted_value, labels)  # Mean squared error loss\n","        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)  # Log loss\n","        return val_loss\n","\n","    def test_step(self, batch, batch_idx):\n","        \"\"\"\n","        Performs a single training step.\n","        \"\"\"\n","        input_ids = batch['input_ids']\n","        # attention_mask = batch['attention_mask']\n","        # labels = torch.reshape(batch['label'], (-1, 1))\n","        labels = batch[\"label\"]\n","\n","        # Forward pass and compute loss\n","        predicted_value = self(input_ids)\n","        predicted_value = predicted_value.view(-1, self.config['vocab_size'])\n","        labels = labels.view(-1)\n","\n","        val_loss = F.cross_entropy(predicted_value, labels)  # Mean squared error loss\n","        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)  # Log loss\n","        return val_loss\n","\n","    def configure_optimizers(self):\n","        \"\"\"\n","        Configures the optimizer for training.\n","        \"\"\"\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)  # AdamW optimizer\n","        return optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9iuKSnrcrQF","executionInfo":{"status":"ok","timestamp":1737651701159,"user_tz":-420,"elapsed":357,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"7fbea996-411e-486a-e4be-e95a25d54069"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 101 ms (started: 2025-01-23 17:01:39 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Train model"],"metadata":{"id":"kzYsmMr-pFCO"}},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":47694,"status":"ok","timestamp":1737652088679,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"Sg2A4IrMl20x","outputId":"8def39d7-be93-4cbe-c122-11b4265fee55"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 47.3 s (started: 2025-01-23 17:07:19 +00:00)\n"]}],"source":["MASTER_CONFIG = {\n","    'batch_size': 2560,\n","    'context_window': 16,\n","    'd_model': 128,\n","    'vocab_size': 65,\n","    \"n_heads\": 8,\n","    \"n_layer\": 4,\n","    \"num_workers\": 1,\n","    \"tokenizer_model\":\"google-bert/bert-base-cased\",\n","    # \"tokenizer_model\":\"FacebookAI/roberta-base\",\n","    \"learning_rate\":1e-4,\n","}\n","# MASTER_CONFIG.update({\n","#     \"vocab_size\": AutoTokenizer.from_pretrained(MASTER_CONFIG[\"tokenizer_model\"]).vocab_size,\n","# })\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# model.to(device)\n","\n","data_module = LLamaDataModule(\n","    data_text=data_text,\n","    config = MASTER_CONFIG\n",")\n","data_module.setup()\n","\n","model = LLamaGeneration(config = MASTER_CONFIG)"]},{"cell_type":"code","source":["sample_training = next(iter(data_module.train_dataloader()))[\"input_ids\"]\n","sample_output = model.forward(input_idx = sample_training)\n"," (\n","    sample_training.shape,\n","    next(iter(data_module.train_dataloader()))[\"label\"].shape,\n","    sample_output.shape,\n","    sample_output.view(-1, MASTER_CONFIG['vocab_size']).shape\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xx0NwWYl55PZ","executionInfo":{"status":"ok","timestamp":1737652108607,"user_tz":-420,"elapsed":19931,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}},"outputId":"a9435a1b-3f0d-42f2-c5f1-a6891c0a3813"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2560, 16]),\n"," torch.Size([2560, 16]),\n"," torch.Size([2560, 16, 65]),\n"," torch.Size([40960, 65]))"]},"metadata":{},"execution_count":31},{"output_type":"stream","name":"stdout","text":["time: 19.9 s (started: 2025-01-23 17:08:06 +00:00)\n"]}]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2210,"status":"ok","timestamp":1737652110814,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"},"user_tz":-420},"id":"BSIRn7iylBWg","outputId":"9a0f4194-f68b-4615-95c0-2e7ca224ac09"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO:lightning.pytorch.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO: You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n","INFO:lightning.pytorch.utilities.rank_zero:You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["time: 2.17 s (started: 2025-01-23 17:08:26 +00:00)\n"]}],"source":["model_checkpoint = ModelCheckpoint(\n","    dirpath='checkpoint/',\n","    monitor=\"val_loss\",\n","    verbose=True,\n","    mode=\"min\",\n","    save_top_k=1\n",")\n","\n","early_stopping = EarlyStopping(\n","    monitor=\"val_loss\",\n","    mode=\"min\",\n","    min_delta=1e-4,\n","    patience=5\n",")\n","\n","callbacks = [model_checkpoint, early_stopping, ModelSummary(max_depth=2)]\n","\n","trainer = L.Trainer(\n","    max_epochs=50,\n","    detect_anomaly=True,\n","    callbacks=callbacks\n",")"]},{"cell_type":"code","source":["trainer.fit(model, data_module)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["aee5032c95994bca9a74a4d4b18eefde","1553b2757ff140c3bb6628fe2d0ca71e","70b2173bd7584070a1371c8b0f9dbfc2","a5c4d633724d4a6eb897ce90e3d306e4","779fee3e9f6e477d9c9a43504332d5e2","875578dd07a6485e922ae7b1f4498d60","e75d2d416ad942e8ae7ba8d4be8ef061","24f7afd949bb436c8f3a0b2206c625ef","decd3ece8d534a5ca8ced56bd2fdd140","3444711a32d9488ab4aafb9659a3a4e2","653460432cbd42729a11c8e4ee55ed85","1c64e7075791423f989fb36f385cf385","0c6e33e8a8534fb7b47278531bcbe087","ba3b3a693fd5484e8b54a933cfb76113","72b423421d8445ff90916bb46a739248","05df7c9bbb934dfea6a027db6ad60b33","7b234b1f94724412a1fa5a8dd2714e6e","c4dd0773a3bb4cc38dea082d98f9e316","349bcd789863450eb17e73eb768d8052","7cbd05e220c44d248695636229a4f9fc","d515ff16366a41a39a03dfd04d8cd0bf","c6aef44818744325873e96bf010b26b4","bfc0edb982c840ecbc96a25099994564","1babf61b9b66478e8e7d935dfd8d8eed","234f44e2ca8d4fe7bac3fb3a78b4cd0f","9913abea268d469389935c7b59293b26","96aa28b334754605a406e390422b331e","4b9928c9cabe45ce8a52afe91c527e8a","60f3e9979dda4cdebc4ff963d1060d62","46b8536341e1409696b681f48a608d81","803f67627bdb4ddfaafdd746ac92ff14","57bb3c91ebd94f9f81f2e92f58874c6b","e3638a30e2044dd9a7a5dc5d2e1c93e9","14346622c49f48119b891ab81fcfed1f","19a5356566f1439e9e29680f347f1e72","5205223831924d6086a5114e45cfe19b","d036b89e40304c0baf605698eea41d6f","bf3e800d16e5468ea9aaa31652820837","91019fa2e5c24084890d12bb2ad84494","998f9abbd9fc44b19c577229db5f4b34","df50a683b31e4e94967791c27695ce2d","a0baab19cffe4c1bb2e20272557c9b58","107780f555ec4d518359fe56352f88fc","eec80790c7e849e081333d6d02f41d59","7388753b483c403bbf4bba12322da13a","6541c52641bf47d799bc20492f0f6e8c","18d0adb54c61445b9d62ea17002cd3db","f92d196901584c6e8594c1abe804d6b3","953d622fd5ad44958f598a4a017de6f9","e5f692b2f282485bb1eb6b79303437b6","87bb9cc9322949c880f1acd1cc83604e","d99dc3b4d974412aad4fd6f32ebeed4c","0d3ef564cd06475197d6c1616cebed1d","1c16542354e84644824a34e3d74697af","d388ca50f1b14746837ac0a76e8eb630","4307616e04b642878c784cb0cafc95e4","1916c41234f4490f868015407140023a","2e97aac83bc340cfaeaafc16fb604ca7","8e89c0ce2b03403ea594170fcd240047","7328661bb7504a6fa60744d5daee1007","be16483f413c46b791fd232cec852178","d69808d2f21c4998b0ca9da58b5f9e01","6344faddfed74cd4a72a29a506779ff4","3f01064675dd4af59533fd9d4611220a","3d4fede311b149ab84193f0fa15b1cf4","ff61bd7ed2e44c92bb5f4d7cc1208f8c","f77dba9859c14e65a8fe7c876abb92a1","948180dd69f540bd83fd8ca4068db25f","017d5126e4a245bfab077dabc365bf33","0b37f8820cbe4a6b97bc54864e138143","eecb8257f37046b0a932d87ef34f7b40","ff69572ee0df4b97a6bbec35ad47ab6f","bee2b5dfd2974388acf37aadf849ee5b","caf94a115fc74627bf41453aedfc8725","429c8a64e0a4493abf49389a3f6fb6cd","54ce65f3e4d643e881404240054b82e1","ae328ecc31e74eab80e0a14e0c81173c"]},"id":"qRDzAoZjpSww","outputId":"5a647394-d5ab-4fbc-818f-6eb06a1510c3","executionInfo":{"status":"error","timestamp":1737655115914,"user_tz":-420,"elapsed":3005103,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name                      | Type       | Params | Mode \n","-----------------------------------------------------------------\n","0 | embedding                 | Embedding  | 8.3 K  | train\n","1 | llama_blocks              | Sequential | 2.3 M  | train\n","2 | llama_blocks.llama_block0 | LlamaBlock | 576 K  | train\n","3 | llama_blocks.llama_block1 | LlamaBlock | 576 K  | train\n","4 | llama_blocks.llama_block2 | LlamaBlock | 576 K  | train\n","5 | llama_blocks.llama_block3 | LlamaBlock | 576 K  | train\n","6 | fc_layer                  | Sequential | 57.9 K | train\n","7 | fc_layer.0                | Linear     | 16.5 K | train\n","8 | fc_layer.1                | SwiGLU     | 33.0 K | train\n","9 | fc_layer.2                | Linear     | 8.4 K  | train\n","-----------------------------------------------------------------\n","2.4 M     Trainable params\n","0         Non-trainable params\n","2.4 M     Total params\n","9.481     Total estimated model params size (MB)\n","180       Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name                      | Type       | Params | Mode \n","-----------------------------------------------------------------\n","0 | embedding                 | Embedding  | 8.3 K  | train\n","1 | llama_blocks              | Sequential | 2.3 M  | train\n","2 | llama_blocks.llama_block0 | LlamaBlock | 576 K  | train\n","3 | llama_blocks.llama_block1 | LlamaBlock | 576 K  | train\n","4 | llama_blocks.llama_block2 | LlamaBlock | 576 K  | train\n","5 | llama_blocks.llama_block3 | LlamaBlock | 576 K  | train\n","6 | fc_layer                  | Sequential | 57.9 K | train\n","7 | fc_layer.0                | Linear     | 16.5 K | train\n","8 | fc_layer.1                | SwiGLU     | 33.0 K | train\n","9 | fc_layer.2                | Linear     | 8.4 K  | train\n","-----------------------------------------------------------------\n","2.4 M     Trainable params\n","0         Non-trainable params\n","2.4 M     Total params\n","9.481     Total estimated model params size (MB)\n","180       Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee5032c95994bca9a74a4d4b18eefde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c64e7075791423f989fb36f385cf385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc0edb982c840ecbc96a25099994564"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: Epoch 0, global step 349: 'val_loss' reached 1.95565 (best 1.95565), saving model to '/content/checkpoint/epoch=0-step=349.ckpt' as top 1\n","INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 349: 'val_loss' reached 1.95565 (best 1.95565), saving model to '/content/checkpoint/epoch=0-step=349.ckpt' as top 1\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14346622c49f48119b891ab81fcfed1f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: Epoch 1, global step 698: 'val_loss' reached 1.69394 (best 1.69394), saving model to '/content/checkpoint/epoch=1-step=698.ckpt' as top 1\n","INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 698: 'val_loss' reached 1.69394 (best 1.69394), saving model to '/content/checkpoint/epoch=1-step=698.ckpt' as top 1\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7388753b483c403bbf4bba12322da13a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: Epoch 2, global step 1047: 'val_loss' reached 1.55029 (best 1.55029), saving model to '/content/checkpoint/epoch=2-step=1047.ckpt' as top 1\n","INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 1047: 'val_loss' reached 1.55029 (best 1.55029), saving model to '/content/checkpoint/epoch=2-step=1047.ckpt' as top 1\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4307616e04b642878c784cb0cafc95e4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: Epoch 3, global step 1396: 'val_loss' reached 1.47479 (best 1.47479), saving model to '/content/checkpoint/epoch=3-step=1396.ckpt' as top 1\n","INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 1396: 'val_loss' reached 1.47479 (best 1.47479), saving model to '/content/checkpoint/epoch=3-step=1396.ckpt' as top 1\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77dba9859c14e65a8fe7c876abb92a1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: Epoch 4, global step 1745: 'val_loss' reached 1.42449 (best 1.42449), saving model to '/content/checkpoint/epoch=4-step=1745.ckpt' as top 1\n","INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 1745: 'val_loss' reached 1.42449 (best 1.42449), saving model to '/content/checkpoint/epoch=4-step=1745.ckpt' as top 1\n","INFO: \n","Detected KeyboardInterrupt, attempting graceful shutdown ...\n","INFO:lightning.pytorch.utilities.rank_zero:\n","Detected KeyboardInterrupt, attempting graceful shutdown ...\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'exit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m         )\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused hook - call anyway for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-c7b783e9db94>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Forward pass and compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mpredicted_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mpredicted_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocab_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-c7b783e9db94>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_idx, attention_mask)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllama_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-c7b783e9db94>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# RMS pre-normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a2746e25d225>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Process each attention head and concatenate the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a2746e25d225>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Process each attention head and concatenate the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a2746e25d225>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_attn_weights)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Rotate Q and K using the RoPE matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mq_rotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mk_rotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# fallback to traceback.format_stack()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         return klass._extract_from_extended_frame_gen(\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mextended_frame_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookup_lines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36m_extract_from_extended_frame_gen\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# First call the original checkcache as intended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-7b6b8391c42e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"]},{"output_type":"stream","name":"stdout","text":["time: 50min 5s (started: 2025-01-23 17:08:28 +00:00)\n"]}]},{"cell_type":"code","source":["trainer.test(model, data_module.test_dataloader())"],"metadata":{"id":"aN5laY-Dq2XT","executionInfo":{"status":"aborted","timestamp":1737652032511,"user_tz":-420,"elapsed":3,"user":{"displayName":"Dat Nguyen","userId":"14018828844510355756"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NW9BVUjDGSaF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["VyYUkow1EHCt"],"gpuType":"T4","authorship_tag":"ABX9TyOImV35I4DOgTAMx0BRZr8+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"aee5032c95994bca9a74a4d4b18eefde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1553b2757ff140c3bb6628fe2d0ca71e","IPY_MODEL_70b2173bd7584070a1371c8b0f9dbfc2","IPY_MODEL_a5c4d633724d4a6eb897ce90e3d306e4"],"layout":"IPY_MODEL_779fee3e9f6e477d9c9a43504332d5e2"}},"1553b2757ff140c3bb6628fe2d0ca71e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_875578dd07a6485e922ae7b1f4498d60","placeholder":"","style":"IPY_MODEL_e75d2d416ad942e8ae7ba8d4be8ef061","value":"SanityCheckingDataLoader0:100%"}},"70b2173bd7584070a1371c8b0f9dbfc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_24f7afd949bb436c8f3a0b2206c625ef","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_decd3ece8d534a5ca8ced56bd2fdd140","value":2}},"a5c4d633724d4a6eb897ce90e3d306e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3444711a32d9488ab4aafb9659a3a4e2","placeholder":"","style":"IPY_MODEL_653460432cbd42729a11c8e4ee55ed85","value":"2/2[00:00&lt;00:00,5.36it/s]"}},"779fee3e9f6e477d9c9a43504332d5e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"875578dd07a6485e922ae7b1f4498d60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e75d2d416ad942e8ae7ba8d4be8ef061":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24f7afd949bb436c8f3a0b2206c625ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"decd3ece8d534a5ca8ced56bd2fdd140":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3444711a32d9488ab4aafb9659a3a4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"653460432cbd42729a11c8e4ee55ed85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c64e7075791423f989fb36f385cf385":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c6e33e8a8534fb7b47278531bcbe087","IPY_MODEL_ba3b3a693fd5484e8b54a933cfb76113","IPY_MODEL_72b423421d8445ff90916bb46a739248"],"layout":"IPY_MODEL_05df7c9bbb934dfea6a027db6ad60b33"}},"0c6e33e8a8534fb7b47278531bcbe087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b234b1f94724412a1fa5a8dd2714e6e","placeholder":"","style":"IPY_MODEL_c4dd0773a3bb4cc38dea082d98f9e316","value":"Epoch5:69%"}},"ba3b3a693fd5484e8b54a933cfb76113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_349bcd789863450eb17e73eb768d8052","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cbd05e220c44d248695636229a4f9fc","value":240}},"72b423421d8445ff90916bb46a739248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d515ff16366a41a39a03dfd04d8cd0bf","placeholder":"","style":"IPY_MODEL_c6aef44818744325873e96bf010b26b4","value":"240/349[05:45&lt;02:36,0.70it/s,v_num=5,val_loss=1.420,train_loss=1.500]"}},"05df7c9bbb934dfea6a027db6ad60b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"7b234b1f94724412a1fa5a8dd2714e6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4dd0773a3bb4cc38dea082d98f9e316":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"349bcd789863450eb17e73eb768d8052":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cbd05e220c44d248695636229a4f9fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d515ff16366a41a39a03dfd04d8cd0bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6aef44818744325873e96bf010b26b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc0edb982c840ecbc96a25099994564":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1babf61b9b66478e8e7d935dfd8d8eed","IPY_MODEL_234f44e2ca8d4fe7bac3fb3a78b4cd0f","IPY_MODEL_9913abea268d469389935c7b59293b26"],"layout":"IPY_MODEL_96aa28b334754605a406e390422b331e"}},"1babf61b9b66478e8e7d935dfd8d8eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9928c9cabe45ce8a52afe91c527e8a","placeholder":"","style":"IPY_MODEL_60f3e9979dda4cdebc4ff963d1060d62","value":"ValidationDataLoader0:100%"}},"234f44e2ca8d4fe7bac3fb3a78b4cd0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b8536341e1409696b681f48a608d81","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_803f67627bdb4ddfaafdd746ac92ff14","value":44}},"9913abea268d469389935c7b59293b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57bb3c91ebd94f9f81f2e92f58874c6b","placeholder":"","style":"IPY_MODEL_e3638a30e2044dd9a7a5dc5d2e1c93e9","value":"44/44[00:06&lt;00:00,6.76it/s]"}},"96aa28b334754605a406e390422b331e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"4b9928c9cabe45ce8a52afe91c527e8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f3e9979dda4cdebc4ff963d1060d62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46b8536341e1409696b681f48a608d81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"803f67627bdb4ddfaafdd746ac92ff14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57bb3c91ebd94f9f81f2e92f58874c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3638a30e2044dd9a7a5dc5d2e1c93e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14346622c49f48119b891ab81fcfed1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19a5356566f1439e9e29680f347f1e72","IPY_MODEL_5205223831924d6086a5114e45cfe19b","IPY_MODEL_d036b89e40304c0baf605698eea41d6f"],"layout":"IPY_MODEL_bf3e800d16e5468ea9aaa31652820837"}},"19a5356566f1439e9e29680f347f1e72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91019fa2e5c24084890d12bb2ad84494","placeholder":"","style":"IPY_MODEL_998f9abbd9fc44b19c577229db5f4b34","value":"ValidationDataLoader0:100%"}},"5205223831924d6086a5114e45cfe19b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_df50a683b31e4e94967791c27695ce2d","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0baab19cffe4c1bb2e20272557c9b58","value":44}},"d036b89e40304c0baf605698eea41d6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_107780f555ec4d518359fe56352f88fc","placeholder":"","style":"IPY_MODEL_eec80790c7e849e081333d6d02f41d59","value":"44/44[00:06&lt;00:00,6.90it/s]"}},"bf3e800d16e5468ea9aaa31652820837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"91019fa2e5c24084890d12bb2ad84494":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998f9abbd9fc44b19c577229db5f4b34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df50a683b31e4e94967791c27695ce2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0baab19cffe4c1bb2e20272557c9b58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"107780f555ec4d518359fe56352f88fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec80790c7e849e081333d6d02f41d59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7388753b483c403bbf4bba12322da13a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6541c52641bf47d799bc20492f0f6e8c","IPY_MODEL_18d0adb54c61445b9d62ea17002cd3db","IPY_MODEL_f92d196901584c6e8594c1abe804d6b3"],"layout":"IPY_MODEL_953d622fd5ad44958f598a4a017de6f9"}},"6541c52641bf47d799bc20492f0f6e8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5f692b2f282485bb1eb6b79303437b6","placeholder":"","style":"IPY_MODEL_87bb9cc9322949c880f1acd1cc83604e","value":"ValidationDataLoader0:100%"}},"18d0adb54c61445b9d62ea17002cd3db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d99dc3b4d974412aad4fd6f32ebeed4c","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d3ef564cd06475197d6c1616cebed1d","value":44}},"f92d196901584c6e8594c1abe804d6b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c16542354e84644824a34e3d74697af","placeholder":"","style":"IPY_MODEL_d388ca50f1b14746837ac0a76e8eb630","value":"44/44[00:06&lt;00:00,7.24it/s]"}},"953d622fd5ad44958f598a4a017de6f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e5f692b2f282485bb1eb6b79303437b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87bb9cc9322949c880f1acd1cc83604e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d99dc3b4d974412aad4fd6f32ebeed4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d3ef564cd06475197d6c1616cebed1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c16542354e84644824a34e3d74697af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d388ca50f1b14746837ac0a76e8eb630":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4307616e04b642878c784cb0cafc95e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1916c41234f4490f868015407140023a","IPY_MODEL_2e97aac83bc340cfaeaafc16fb604ca7","IPY_MODEL_8e89c0ce2b03403ea594170fcd240047"],"layout":"IPY_MODEL_7328661bb7504a6fa60744d5daee1007"}},"1916c41234f4490f868015407140023a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be16483f413c46b791fd232cec852178","placeholder":"","style":"IPY_MODEL_d69808d2f21c4998b0ca9da58b5f9e01","value":"ValidationDataLoader0:100%"}},"2e97aac83bc340cfaeaafc16fb604ca7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6344faddfed74cd4a72a29a506779ff4","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f01064675dd4af59533fd9d4611220a","value":44}},"8e89c0ce2b03403ea594170fcd240047":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4fede311b149ab84193f0fa15b1cf4","placeholder":"","style":"IPY_MODEL_ff61bd7ed2e44c92bb5f4d7cc1208f8c","value":"44/44[00:06&lt;00:00,6.78it/s]"}},"7328661bb7504a6fa60744d5daee1007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"be16483f413c46b791fd232cec852178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d69808d2f21c4998b0ca9da58b5f9e01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6344faddfed74cd4a72a29a506779ff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f01064675dd4af59533fd9d4611220a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d4fede311b149ab84193f0fa15b1cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff61bd7ed2e44c92bb5f4d7cc1208f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f77dba9859c14e65a8fe7c876abb92a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_948180dd69f540bd83fd8ca4068db25f","IPY_MODEL_017d5126e4a245bfab077dabc365bf33","IPY_MODEL_0b37f8820cbe4a6b97bc54864e138143"],"layout":"IPY_MODEL_eecb8257f37046b0a932d87ef34f7b40"}},"948180dd69f540bd83fd8ca4068db25f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff69572ee0df4b97a6bbec35ad47ab6f","placeholder":"","style":"IPY_MODEL_bee2b5dfd2974388acf37aadf849ee5b","value":"ValidationDataLoader0:100%"}},"017d5126e4a245bfab077dabc365bf33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_caf94a115fc74627bf41453aedfc8725","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_429c8a64e0a4493abf49389a3f6fb6cd","value":44}},"0b37f8820cbe4a6b97bc54864e138143":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ce65f3e4d643e881404240054b82e1","placeholder":"","style":"IPY_MODEL_ae328ecc31e74eab80e0a14e0c81173c","value":"44/44[00:06&lt;00:00,6.77it/s]"}},"eecb8257f37046b0a932d87ef34f7b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ff69572ee0df4b97a6bbec35ad47ab6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee2b5dfd2974388acf37aadf849ee5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caf94a115fc74627bf41453aedfc8725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"429c8a64e0a4493abf49389a3f6fb6cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54ce65f3e4d643e881404240054b82e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae328ecc31e74eab80e0a14e0c81173c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}